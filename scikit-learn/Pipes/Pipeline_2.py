{"metadata":{"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Create a pipeline that extracts features from the data then creates a model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectKBest\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\n \n# data laoded into global variables\nurl_data = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\nvarnames = ['var_preg', 'var_plas', 'var_pres', 'var_skin', 'var_test', 'var_mass', 'var_pedi', 'var_age', 'var_class']\nvardataframe = read_csv(url_data, names=varnames)\nvararray = vardataframe.values\nvarX = vararray[:,0:8]\nvarY = vararray[:,8]\n \n# creating feature union\nurlfeatures = []\nurlfeatures.append(('pca', PCA(n_components=3)))\nurlfeatures.append(('select_best', SelectKBest(k=6)))\nfeature_union = FeatureUnion(urlfeatures)\n \n# Here, pipeline is created\nestimators = []\nestimators.append(('feature_union', feature_union))\nestimators.append(('logistic', LogisticRegression()))\nmodel = Pipeline(estimators)\n \n# The pipelie is tested here\nseed = 7\nvarkfold = KFold(n_splits=10)\ndataresults = cross_val_score(model, varX, varY, cv=varkfold)\nprint(dataresults.mean())\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.tree import DecisionTreeClassifier\n# database is imported from inbuilt sklearn datasets\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n \n#The data spliting is executed here\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.50)\n# importing pipes for making the Pipe flow\nfrom sklearn.pipeline import Pipeline\n# The sequence of pipe flow is :\n# PCA dimension is reduced by 2 >> Data gets scaled >> Classification of decission tree\npipe = Pipeline([('pca', PCA(n_components = 2)), ('std', StandardScaler()), ('decision_tree', DecisionTreeClassifier())], verbose = True)\n \n# fitting the data in the pipeline\npipe.fit(X_train, y_train)\n\n# making prediction\npred = pipe.predict(X_test)\n\n#Plot\n#Encoding color mapping\niris_type = [iris['target_names'][i] if target == 0: i=0]#; elif target == 1: i=1 else: i=2]\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12,8))\nplt.scatter(x = range(0,76), y = pred, c = iris_type)\n\n# scoring data\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, pipe.predict(X_test)))","metadata":{},"execution_count":null,"outputs":[],"id":"60502d6a-93a4-437a-9e29-caaeaf4fe106"}]}
