{"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#if str(input(environment)) == 'venv':\n#    %python pip install numpy\n#    %python pip install matplotlib\n#elif str(input(environment)) == 'conda':    \n#    %conda install numpy \n#    %conda install matplotlib\n#else:\n#    install numpy\n#    install matplotlib\n#    break","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n\ndf  = pd.read_csv(\"creditcard.csv\")[:80_000]\ndf.head()","metadata":{"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62    0.0  \n1  0.125895 -0.008983  0.014724    2.69    0.0  \n2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n3 -0.221929  0.062723  0.061458  123.50    0.0  \n4  0.502292  0.219422  0.215153   69.99    0.0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.drop(columns=['Time', 'Amount', 'Class']).values","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"y = df['Class'].values","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"y.sum()","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"196.0"},"metadata":{}}]},{"cell_type":"code","source":"f\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\"","metadata":{},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'Shapes of X=(80000, 28) y=(80000,), #Fraud Cases=196'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Grid Search Cross Validated Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmod = LogisticRegression(max_iter=1000)\nf\" Predicted cases of non-fraud: {mod.fit(X, y).predict(X).sum()}. We see that model mistakenly caught up false cases. Lets add weights.\"","metadata":{},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"' Predicted cases of non-fraud: 151. We see that model mistakenly caught up false cases. Lets add weights.'"},"metadata":{}}]},{"cell_type":"code","source":"mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\nf\" Predicted 'true' cases : {mod.fit(X, y).predict(X).sum()} .\"","metadata":{},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\" Predicted 'true' cases : 171 .\""},"metadata":{}}]},{"cell_type":"code","source":"lr = LogisticRegression()","metadata":{},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#??lr.fit","metadata":{},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#??lr.fit.score","metadata":{},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\n\ngrid = GridSearchCV(estimator = LogisticRegression(max_iter=1000),\n    param_grid = {'class_weight': [{0: 1, 1: v} for v in range(1, 4)]}, \n    cv = 4,\n    n_jobs = -1)\ngrid.fit(X, y)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n                                          {0: 1, 1: 3}]})"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, make_scorer\n\nrecall_score(y, grid.predict(X))","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"0.5918367346938775"},"metadata":{}}]},{"cell_type":"markdown","source":"___________________________________\nTime spent on validating grid model.\n____________________________________","metadata":{}},{"cell_type":"code","source":"_","metadata":{},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.5918367346938775"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(grid.cv_results_)","metadata":{"tags":[]},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       9.776741      1.781958         0.049199        0.043107   \n1       8.175514      2.106312         0.022942        0.032361   \n2      11.203808      2.198481         0.021226        0.026632   \n\n  param_class_weight                          params  split0_test_score  \\\n0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}            0.99405   \n1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}            0.99025   \n2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}            0.98730   \n\n   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n0            0.99835            0.99945            0.99780         0.997413   \n1            0.99840            0.99960            0.99805         0.996575   \n2            0.99845            0.99960            0.99815         0.995875   \n\n   std_test_score  rank_test_score  \n0        0.002030                1  \n1        0.003697                2  \n2        0.004980                3  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_class_weight</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9.776741</td>\n      <td>1.781958</td>\n      <td>0.049199</td>\n      <td>0.043107</td>\n      <td>{0: 1, 1: 1}</td>\n      <td>{'class_weight': {0: 1, 1: 1}}</td>\n      <td>0.99405</td>\n      <td>0.99835</td>\n      <td>0.99945</td>\n      <td>0.99780</td>\n      <td>0.997413</td>\n      <td>0.002030</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8.175514</td>\n      <td>2.106312</td>\n      <td>0.022942</td>\n      <td>0.032361</td>\n      <td>{0: 1, 1: 2}</td>\n      <td>{'class_weight': {0: 1, 1: 2}}</td>\n      <td>0.99025</td>\n      <td>0.99840</td>\n      <td>0.99960</td>\n      <td>0.99805</td>\n      <td>0.996575</td>\n      <td>0.003697</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11.203808</td>\n      <td>2.198481</td>\n      <td>0.021226</td>\n      <td>0.026632</td>\n      <td>{0: 1, 1: 3}</td>\n      <td>{'class_weight': {0: 1, 1: 3}}</td>\n      <td>0.98730</td>\n      <td>0.99845</td>\n      <td>0.99960</td>\n      <td>0.99815</td>\n      <td>0.995875</td>\n      <td>0.004980</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(grid.cv_results_).columns","metadata":{},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n       'param_class_weight', 'params', 'split0_test_score',\n       'split1_test_score', 'split2_test_score', 'split3_test_score',\n       'mean_test_score', 'std_test_score', 'rank_test_score'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"fit = grid.fit(X,y)","metadata":{},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)","metadata":{},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"_","metadata":{},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n       'param_class_weight', 'params', 'split0_test_score',\n       'split1_test_score', 'split2_test_score', 'split3_test_score',\n       'mean_test_score', 'std_test_score', 'rank_test_score'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Plot 1","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\ndf = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_score']:\n    plt.plot([_[1] for _ in df['param_class_weight']],\n            df[score],\n            label = score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"_____________________________________","metadata":{}},{"cell_type":"markdown","source":"We have added precision.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import make_scorer, precision_score, recall_score \n\ngrid = GridSearchCV(estimator = LogisticRegression(max_iter=1000),\n    param_grid = {'class_weight': [{0: 1, 1: v} for v in range(1, 4)]},\n    scoring = {'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)},\n    refit = 'precision',\n    cv = 4,\n    n_jobs = -1)\ngrid.fit(X, y)","metadata":{"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(cv=4, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n             param_grid={'class_weight': [{0: 1, 1: 1}, {0: 1, 1: 2},\n                                          {0: 1, 1: 3}]},\n             refit='precision',\n             scoring={'precision': make_scorer(precision_score),\n                      'recall_score': make_scorer(recall_score)})"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(grid.cv_results_)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0       7.185069      1.441042         0.104096        0.024372   \n1       6.630035      1.596930         0.100972        0.053314   \n2       7.168279      1.780674         0.107387        0.001515   \n\n  param_class_weight                          params  split0_test_precision  \\\n0       {0: 1, 1: 1}  {'class_weight': {0: 1, 1: 1}}               0.281250   \n1       {0: 1, 1: 2}  {'class_weight': {0: 1, 1: 2}}               0.190678   \n2       {0: 1, 1: 3}  {'class_weight': {0: 1, 1: 3}}               0.154882   \n\n   split1_test_precision  split2_test_precision  split3_test_precision  \\\n0                    1.0               0.952381               0.857143   \n1                    1.0               0.955556               0.812500   \n2                    1.0               0.955556               0.800000   \n\n   mean_test_precision  std_test_precision  rank_test_precision  \\\n0             0.772693            0.288359                    1   \n1             0.739683            0.324451                    2   \n2             0.727609            0.338900                    3   \n\n   split0_test_recall_score  split1_test_recall_score  \\\n0                  0.918367                  0.326531   \n1                  0.918367                  0.346939   \n2                  0.938776                  0.367347   \n\n   split2_test_recall_score  split3_test_recall_score  mean_test_recall_score  \\\n0                  0.816327                  0.122449                0.545918   \n1                  0.877551                  0.265306                0.602041   \n2                  0.877551                  0.326531                0.627551   \n\n   std_test_recall_score  rank_test_recall_score  \n0               0.331397                       3  \n1               0.297672                       2  \n2               0.281816                       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_class_weight</th>\n      <th>params</th>\n      <th>split0_test_precision</th>\n      <th>split1_test_precision</th>\n      <th>split2_test_precision</th>\n      <th>split3_test_precision</th>\n      <th>mean_test_precision</th>\n      <th>std_test_precision</th>\n      <th>rank_test_precision</th>\n      <th>split0_test_recall_score</th>\n      <th>split1_test_recall_score</th>\n      <th>split2_test_recall_score</th>\n      <th>split3_test_recall_score</th>\n      <th>mean_test_recall_score</th>\n      <th>std_test_recall_score</th>\n      <th>rank_test_recall_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.185069</td>\n      <td>1.441042</td>\n      <td>0.104096</td>\n      <td>0.024372</td>\n      <td>{0: 1, 1: 1}</td>\n      <td>{'class_weight': {0: 1, 1: 1}}</td>\n      <td>0.281250</td>\n      <td>1.0</td>\n      <td>0.952381</td>\n      <td>0.857143</td>\n      <td>0.772693</td>\n      <td>0.288359</td>\n      <td>1</td>\n      <td>0.918367</td>\n      <td>0.326531</td>\n      <td>0.816327</td>\n      <td>0.122449</td>\n      <td>0.545918</td>\n      <td>0.331397</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.630035</td>\n      <td>1.596930</td>\n      <td>0.100972</td>\n      <td>0.053314</td>\n      <td>{0: 1, 1: 2}</td>\n      <td>{'class_weight': {0: 1, 1: 2}}</td>\n      <td>0.190678</td>\n      <td>1.0</td>\n      <td>0.955556</td>\n      <td>0.812500</td>\n      <td>0.739683</td>\n      <td>0.324451</td>\n      <td>2</td>\n      <td>0.918367</td>\n      <td>0.346939</td>\n      <td>0.877551</td>\n      <td>0.265306</td>\n      <td>0.602041</td>\n      <td>0.297672</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.168279</td>\n      <td>1.780674</td>\n      <td>0.107387</td>\n      <td>0.001515</td>\n      <td>{0: 1, 1: 3}</td>\n      <td>{'class_weight': {0: 1, 1: 3}}</td>\n      <td>0.154882</td>\n      <td>1.0</td>\n      <td>0.955556</td>\n      <td>0.800000</td>\n      <td>0.727609</td>\n      <td>0.338900</td>\n      <td>3</td>\n      <td>0.938776</td>\n      <td>0.367347</td>\n      <td>0.877551</td>\n      <td>0.326531</td>\n      <td>0.627551</td>\n      <td>0.281816</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.DataFrame(grid.cv_results_).columns","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n       'param_class_weight', 'params', 'split0_test_precision',\n       'split1_test_precision', 'split2_test_precision',\n       'split3_test_precision', 'mean_test_precision', 'std_test_precision',\n       'rank_test_precision', 'split0_test_recall_score',\n       'split1_test_recall_score', 'split2_test_recall_score',\n       'split3_test_recall_score', 'mean_test_recall_score',\n       'std_test_recall_score', 'rank_test_recall_score'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model enhanced","metadata":{}},{"cell_type":"markdown","source":"### Refit precision","metadata":{}},{"cell_type":"markdown","source":"__________________________________","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, make_scorer\n\nfor v in range(5,10):\n    grid = GridSearchCV(estimator = LogisticRegression(max_iter=1000),\n        param_grid = {'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n        scoring = {'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)},\n        refit = 'precision',\n        return_train_score = True,\n        cv = v,\n        n_jobs = -1)\nprint(\"iteration\",v, grid.fit(X, y))","metadata":{"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, make_scorer\n\ngrid = GridSearchCV(estimator = LogisticRegression(max_iter=1000),\n    param_grid = {'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n    scoring = {'precision': make_scorer(precision_score), 'recall_score': make_scorer(recall_score)},\n    refit = 'precision',\n    return_train_score = True,\n    cv = 10,\n    n_jobs = -1)\ngrid.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot 2","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\ndf = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall_score','mean_test_precision']:\n    plt.plot([_[1] for _ in df['param_class_weight']],\n            df[score],\n            label = score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot 3","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\ndf = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_train_recall_score','mean_train_precision']:\n    plt.plot(x = [_[1] for _ in df['param_class_weight']],\n            y = df[score.replace('test','train')],\n            label = score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Definition of precision recalling function ","metadata":{}},{"cell_type":"code","source":"def min_recall_precision(y_true, y_pred):\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def min_recall_precision(y_true, y_pred):\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\nmake_scorer(min_recall_precision, greater_is_better=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ?make_scorer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# s = make_scorer(min_recall_precision)\n# ??s","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"____________________","metadata":{}},{"cell_type":"markdown","source":"### Choose minimal recall rate and precision level","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\ndef min_recall_precision(y_true, y_pred):\n    recall= recall_score(y_true, y_pred)\n    precision=precision_score(y_true, y_pred)\n    return mon(recall, precision)\n\ngrid = GridSearchCV(estimator = LogisticRegression(max_iter=1000),\n    param_grid = {'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n    scoring = {'precision': make_scorer(precision_score), \n               'recall_score': make_scorer(recall_score),\n              'min_both': make_scorer(min_recall_precision)},               \n    refit = 'min_both',\n    return_train_score = True,\n    cv = 10,\n    n_jobs = -1)\ngrid.fit(X, y);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = make_scorer(min_recall_precision)\n??s","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot 5","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\ndf = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall_score','mean_test_precision', 'mean_test_min_both']:\n    plt.plot([_[1] for _ in df['param_class_weight']],\n            y = df[score],\n            label = score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, make_scorer\n\ndef min_recall_precision(est, X, y_true, sample_weight=None):\n    y_pred = est.predict(X)\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\ngrid = GridSearchCV(\n    estimator=LogisticRegression(max_iter=1000),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n    scoring={'precision': make_scorer(precision_score), \n             'recall': make_scorer(recall_score),\n             'min_both': min_recall_precision},\n    refit='min_both',\n    return_train_score=True,\n    cv=10,\n    n_jobs=-1\n)\nif str(input(weight))== 'added':\ngrid.fit(X, y);\nelse:\ngrid.fit(X, y, sample_weight = np.log(1+ df['Amount']));","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a summary for the test metrics.","metadata":{}},{"cell_type":"markdown","source":"# Plot 6","metadata":{}},{"cell_type":"code","source":"plt.subplot(1,2,1)\nplt.figure(figsize=(12,4))\ndf = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall','mean_test_precision', 'mean_test_min_both']:\n    plt.plot([_[1] for _ in df['param_class_weight']],\n            y = df[score],\n            label = score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here's the train metrics.","metadata":{}},{"cell_type":"code","source":"plt.subplot(1,2,2)\nplt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_train_recall', 'mean_train_precision', 'mean_test_min_both']:\n    plt.scatter(x=[_[1] for _ in df_results['param_class_weight']], \n                y=df_results[score.replace('test', 'train')], \n                label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Outlier Detection Models","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.ensemble import IsolationForest\nmod = IsolationForest().fit(X); print(\"Prediction: \", mod.predict(X), \".\")\n#how frequent predicted outliers\nCounter(mod.predict(X))\n\nnp.where(mod.predict(X) == -1, 1, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now in a gridsearch.","metadata":{}},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == -1, 1, 0))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == -1, 1, 0))\n\ngrid = GridSearchCV(\n    estimator=IsolationForest(),\n    param_grid={'contamination': np.linspace(0.001, 0.02, 10)},\n    scoring={'precision': outlier_precision, \n             'recall': outlier_recall},\n    refit='precision',\n    cv=5,\n    n_jobs=-1\n)\ngrid.fit(X, y);\n\nplt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall', 'mean_test_precision']:\n    plt.plot(df_results['param_contamination'], \n             df_results[score], \n             label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def min_pre_rec(y, y_true):\n    return min(recall_score(y, y_true), precision_score(y, y_true))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == 1, 0, 1))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == 1, 0, 1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(\n    estimator=LogisticRegression(class_weight=10),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 40, t5)]},\n    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'min_pre_rec': make_scorer(min_pre_rec)},\n    refit='precision',\n    cv = 10,\n    n_jobs=-1\n)\ngrid.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_min_pre_rec']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = make_scorer(recall_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \n\nnp.eye(4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"1 + 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}