{"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# $ python -m pip install numpy\n# $ python -m pip install pandas\n# $ python -m pip install matplotlib\n# $ python -m pip install scikit-learn\n# $ python -m pip install keras\n# $ python -m pip install tensorflow\n%whos","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n\nbinder=0\nif bool(input(binder))== True:\n    df = pd.read_csv(\"creditcard.csv\")\nelse:\n    df  = pd.read_csv(\"C:/Users/Lenovo/OneDrive/Data Science project/Python.Data.Science/scikit-learn/scikit-metrics/creditcard.csv\")[:80_000]\ndf.head(5)","metadata":{"scrolled":true,"tags":[],"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdin","text":"0 True\n"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.drop(columns=['Time', 'Amount', 'Class']).values\ny = df['Class'].values\nf\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\"","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'Shapes of X=(284807, 28) y=(284807,), #Fraud Cases=492'"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n??GridSearchCV","metadata":{"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m\n\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mSource:\u001b[0m        \n\u001b[0;32mclass\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSearchCV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Exhaustive search over specified parameter values for an estimator.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Important members are fit, predict.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    GridSearchCV implements a \"fit\" and a \"score\" method.\u001b[0m\n\u001b[0;34m    It also implements \"score_samples\", \"predict\", \"predict_proba\",\u001b[0m\n\u001b[0;34m    \"decision_function\", \"transform\" and \"inverse_transform\" if they are\u001b[0m\n\u001b[0;34m    implemented in the estimator used.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    The parameters of the estimator used to apply these methods are optimized\u001b[0m\n\u001b[0;34m    by cross-validated grid-search over a parameter grid.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Read more in the :ref:`User Guide <grid_search>`.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Parameters\u001b[0m\n\u001b[0;34m    ----------\u001b[0m\n\u001b[0;34m    estimator : estimator object.\u001b[0m\n\u001b[0;34m        This is assumed to implement the scikit-learn estimator interface.\u001b[0m\n\u001b[0;34m        Either estimator needs to provide a ``score`` function,\u001b[0m\n\u001b[0;34m        or ``scoring`` must be passed.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    param_grid : dict or list of dictionaries\u001b[0m\n\u001b[0;34m        Dictionary with parameters names (`str`) as keys and lists of\u001b[0m\n\u001b[0;34m        parameter settings to try as values, or a list of such\u001b[0m\n\u001b[0;34m        dictionaries, in which case the grids spanned by each dictionary\u001b[0m\n\u001b[0;34m        in the list are explored. This enables searching over any sequence\u001b[0m\n\u001b[0;34m        of parameter settings.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    scoring : str, callable, list, tuple or dict, default=None\u001b[0m\n\u001b[0;34m        Strategy to evaluate the performance of the cross-validated model on\u001b[0m\n\u001b[0;34m        the test set.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        If `scoring` represents a single score, one can use:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        - a single string (see :ref:`scoring_parameter`);\u001b[0m\n\u001b[0;34m        - a callable (see :ref:`scoring`) that returns a single value.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        If `scoring` represents multiple scores, one can use:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        - a list or tuple of unique strings;\u001b[0m\n\u001b[0;34m        - a callable returning a dictionary where the keys are the metric\u001b[0m\n\u001b[0;34m          names and the values are the metric scores;\u001b[0m\n\u001b[0;34m        - a dictionary with metric names as keys and callables a values.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        See :ref:`multimetric_grid_search` for an example.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    n_jobs : int, default=None\u001b[0m\n\u001b[0;34m        Number of jobs to run in parallel.\u001b[0m\n\u001b[0;34m        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\u001b[0m\n\u001b[0;34m        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\u001b[0m\n\u001b[0;34m        for more details.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionchanged:: v0.20\u001b[0m\n\u001b[0;34m           `n_jobs` default changed from 1 to None\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    refit : bool, str, or callable, default=True\u001b[0m\n\u001b[0;34m        Refit an estimator using the best found parameters on the whole\u001b[0m\n\u001b[0;34m        dataset.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multiple metric evaluation, this needs to be a `str` denoting the\u001b[0m\n\u001b[0;34m        scorer that would be used to find the best parameters for refitting\u001b[0m\n\u001b[0;34m        the estimator at the end.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Where there are considerations other than maximum score in\u001b[0m\n\u001b[0;34m        choosing a best estimator, ``refit`` can be set to a function which\u001b[0m\n\u001b[0;34m        returns the selected ``best_index_`` given ``cv_results_``. In that\u001b[0m\n\u001b[0;34m        case, the ``best_estimator_`` and ``best_params_`` will be set\u001b[0m\n\u001b[0;34m        according to the returned ``best_index_`` while the ``best_score_``\u001b[0m\n\u001b[0;34m        attribute will not be available.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        The refitted estimator is made available at the ``best_estimator_``\u001b[0m\n\u001b[0;34m        attribute and permits using ``predict`` directly on this\u001b[0m\n\u001b[0;34m        ``GridSearchCV`` instance.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Also for multiple metric evaluation, the attributes ``best_index_``,\u001b[0m\n\u001b[0;34m        ``best_score_`` and ``best_params_`` will only be available if\u001b[0m\n\u001b[0;34m        ``refit`` is set and all of them will be determined w.r.t this specific\u001b[0m\n\u001b[0;34m        scorer.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        See ``scoring`` parameter to know more about multiple metric\u001b[0m\n\u001b[0;34m        evaluation.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionchanged:: 0.20\u001b[0m\n\u001b[0;34m            Support for callable added.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    cv : int, cross-validation generator or an iterable, default=None\u001b[0m\n\u001b[0;34m        Determines the cross-validation splitting strategy.\u001b[0m\n\u001b[0;34m        Possible inputs for cv are:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        - None, to use the default 5-fold cross validation,\u001b[0m\n\u001b[0;34m        - integer, to specify the number of folds in a `(Stratified)KFold`,\u001b[0m\n\u001b[0;34m        - :term:`CV splitter`,\u001b[0m\n\u001b[0;34m        - An iterable yielding (train, test) splits as arrays of indices.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For integer/None inputs, if the estimator is a classifier and ``y`` is\u001b[0m\n\u001b[0;34m        either binary or multiclass, :class:`StratifiedKFold` is used. In all\u001b[0m\n\u001b[0;34m        other cases, :class:`KFold` is used. These splitters are instantiated\u001b[0m\n\u001b[0;34m        with `shuffle=False` so the splits will be the same across calls.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        Refer :ref:`User Guide <cross_validation>` for the various\u001b[0m\n\u001b[0;34m        cross-validation strategies that can be used here.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionchanged:: 0.22\u001b[0m\n\u001b[0;34m            ``cv`` default value if None changed from 3-fold to 5-fold.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    verbose : int\u001b[0m\n\u001b[0;34m        Controls the verbosity: the higher, the more messages.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        - >1 : the computation time for each fold and parameter candidate is\u001b[0m\n\u001b[0;34m          displayed;\u001b[0m\n\u001b[0;34m        - >2 : the score is also displayed;\u001b[0m\n\u001b[0;34m        - >3 : the fold and candidate parameter indexes are also displayed\u001b[0m\n\u001b[0;34m          together with the starting time of the computation.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    pre_dispatch : int, or str, default=n_jobs\u001b[0m\n\u001b[0;34m        Controls the number of jobs that get dispatched during parallel\u001b[0m\n\u001b[0;34m        execution. Reducing this number can be useful to avoid an\u001b[0m\n\u001b[0;34m        explosion of memory consumption when more jobs get dispatched\u001b[0m\n\u001b[0;34m        than CPUs can process. This parameter can be:\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m            - None, in which case all the jobs are immediately\u001b[0m\n\u001b[0;34m              created and spawned. Use this for lightweight and\u001b[0m\n\u001b[0;34m              fast-running jobs, to avoid delays due to on-demand\u001b[0m\n\u001b[0;34m              spawning of the jobs\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m            - An int, giving the exact number of total jobs that are\u001b[0m\n\u001b[0;34m              spawned\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m            - A str, giving an expression as a function of n_jobs,\u001b[0m\n\u001b[0;34m              as in '2*n_jobs'\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    error_score : 'raise' or numeric, default=np.nan\u001b[0m\n\u001b[0;34m        Value to assign to the score if an error occurs in estimator fitting.\u001b[0m\n\u001b[0;34m        If set to 'raise', the error is raised. If a numeric value is given,\u001b[0m\n\u001b[0;34m        FitFailedWarning is raised. This parameter does not affect the refit\u001b[0m\n\u001b[0;34m        step, which will always raise the error.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    return_train_score : bool, default=False\u001b[0m\n\u001b[0;34m        If ``False``, the ``cv_results_`` attribute will not include training\u001b[0m\n\u001b[0;34m        scores.\u001b[0m\n\u001b[0;34m        Computing training scores is used to get insights on how different\u001b[0m\n\u001b[0;34m        parameter settings impact the overfitting/underfitting trade-off.\u001b[0m\n\u001b[0;34m        However computing the scores on the training set can be computationally\u001b[0m\n\u001b[0;34m        expensive and is not strictly required to select the parameters that\u001b[0m\n\u001b[0;34m        yield the best generalization performance.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionadded:: 0.19\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionchanged:: 0.21\u001b[0m\n\u001b[0;34m            Default value was changed from ``True`` to ``False``\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Examples\u001b[0m\n\u001b[0;34m    --------\u001b[0m\n\u001b[0;34m    >>> from sklearn import svm, datasets\u001b[0m\n\u001b[0;34m    >>> from sklearn.model_selection import GridSearchCV\u001b[0m\n\u001b[0;34m    >>> iris = datasets.load_iris()\u001b[0m\n\u001b[0;34m    >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\u001b[0m\n\u001b[0;34m    >>> svc = svm.SVC()\u001b[0m\n\u001b[0;34m    >>> clf = GridSearchCV(svc, parameters)\u001b[0m\n\u001b[0;34m    >>> clf.fit(iris.data, iris.target)\u001b[0m\n\u001b[0;34m    GridSearchCV(estimator=SVC(),\u001b[0m\n\u001b[0;34m                 param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\u001b[0m\n\u001b[0;34m    >>> sorted(clf.cv_results_.keys())\u001b[0m\n\u001b[0;34m    ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\u001b[0m\n\u001b[0;34m     'param_C', 'param_kernel', 'params',...\u001b[0m\n\u001b[0;34m     'rank_test_score', 'split0_test_score',...\u001b[0m\n\u001b[0;34m     'split2_test_score', ...\u001b[0m\n\u001b[0;34m     'std_fit_time', 'std_score_time', 'std_test_score']\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Attributes\u001b[0m\n\u001b[0;34m    ----------\u001b[0m\n\u001b[0;34m    cv_results_ : dict of numpy (masked) ndarrays\u001b[0m\n\u001b[0;34m        A dict with keys as column headers and values as columns, that can be\u001b[0m\n\u001b[0;34m        imported into a pandas ``DataFrame``.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For instance the below given table\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        +------------+-----------+------------+-----------------+---+---------+\u001b[0m\n\u001b[0;34m        |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\u001b[0m\n\u001b[0;34m        +============+===========+============+=================+===+=========+\u001b[0m\n\u001b[0;34m        |  'poly'    |     --    |      2     |       0.80      |...|    2    |\u001b[0m\n\u001b[0;34m        +------------+-----------+------------+-----------------+---+---------+\u001b[0m\n\u001b[0;34m        |  'poly'    |     --    |      3     |       0.70      |...|    4    |\u001b[0m\n\u001b[0;34m        +------------+-----------+------------+-----------------+---+---------+\u001b[0m\n\u001b[0;34m        |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\u001b[0m\n\u001b[0;34m        +------------+-----------+------------+-----------------+---+---------+\u001b[0m\n\u001b[0;34m        |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\u001b[0m\n\u001b[0;34m        +------------+-----------+------------+-----------------+---+---------+\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        will be represented by a ``cv_results_`` dict of::\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m            {\u001b[0m\n\u001b[0;34m            'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\u001b[0m\n\u001b[0;34m                                         mask = [False False False False]...)\u001b[0m\n\u001b[0;34m            'param_gamma': masked_array(data = [-- -- 0.1 0.2],\u001b[0m\n\u001b[0;34m                                        mask = [ True  True False False]...),\u001b[0m\n\u001b[0;34m            'param_degree': masked_array(data = [2.0 3.0 -- --],\u001b[0m\n\u001b[0;34m                                         mask = [False False  True  True]...),\u001b[0m\n\u001b[0;34m            'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\u001b[0m\n\u001b[0;34m            'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\u001b[0m\n\u001b[0;34m            'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\u001b[0m\n\u001b[0;34m            'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\u001b[0m\n\u001b[0;34m            'rank_test_score'    : [2, 4, 3, 1],\u001b[0m\n\u001b[0;34m            'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\u001b[0m\n\u001b[0;34m            'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\u001b[0m\n\u001b[0;34m            'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\u001b[0m\n\u001b[0;34m            'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\u001b[0m\n\u001b[0;34m            'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\u001b[0m\n\u001b[0;34m            'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\u001b[0m\n\u001b[0;34m            'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\u001b[0m\n\u001b[0;34m            'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\u001b[0m\n\u001b[0;34m            'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\u001b[0m\n\u001b[0;34m            }\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        NOTE\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        The key ``'params'`` is used to store a list of parameter\u001b[0m\n\u001b[0;34m        settings dicts for all the parameter candidates.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\u001b[0m\n\u001b[0;34m        ``std_score_time`` are all in seconds.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multi-metric evaluation, the scores for all the scorers are\u001b[0m\n\u001b[0;34m        available in the ``cv_results_`` dict at the keys ending with that\u001b[0m\n\u001b[0;34m        scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\u001b[0m\n\u001b[0;34m        above. ('split0_test_precision', 'mean_train_precision' etc.)\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    best_estimator_ : estimator\u001b[0m\n\u001b[0;34m        Estimator that was chosen by the search, i.e. estimator\u001b[0m\n\u001b[0;34m        which gave highest score (or smallest loss if specified)\u001b[0m\n\u001b[0;34m        on the left out data. Not available if ``refit=False``.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        See ``refit`` parameter for more information on allowed values.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    best_score_ : float\u001b[0m\n\u001b[0;34m        Mean cross-validated score of the best_estimator\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[0m\n\u001b[0;34m        specified.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        This attribute is not available if ``refit`` is a function.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    best_params_ : dict\u001b[0m\n\u001b[0;34m        Parameter setting that gave the best results on the hold out data.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[0m\n\u001b[0;34m        specified.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    best_index_ : int\u001b[0m\n\u001b[0;34m        The index (of the ``cv_results_`` arrays) which corresponds to the best\u001b[0m\n\u001b[0;34m        candidate parameter setting.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        The dict at ``search.cv_results_['params'][search.best_index_]`` gives\u001b[0m\n\u001b[0;34m        the parameter setting for the best model, that gives the highest\u001b[0m\n\u001b[0;34m        mean score (``search.best_score_``).\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multi-metric evaluation, this is present only if ``refit`` is\u001b[0m\n\u001b[0;34m        specified.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    scorer_ : function or a dict\u001b[0m\n\u001b[0;34m        Scorer function used on the held out data to choose the best\u001b[0m\n\u001b[0;34m        parameters for the model.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        For multi-metric evaluation, this attribute holds the validated\u001b[0m\n\u001b[0;34m        ``scoring`` dict which maps the scorer key to the scorer callable.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    n_splits_ : int\u001b[0m\n\u001b[0;34m        The number of cross-validation splits (folds/iterations).\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    refit_time_ : float\u001b[0m\n\u001b[0;34m        Seconds used for refitting the best model on the whole dataset.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        This is present only if ``refit`` is not False.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m        .. versionadded:: 0.20\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    multimetric_ : bool\u001b[0m\n\u001b[0;34m        Whether or not the scorers compute several metrics.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    Notes\u001b[0m\n\u001b[0;34m    -----\u001b[0m\n\u001b[0;34m    The parameters selected are those that maximize the score of the left out\u001b[0m\n\u001b[0;34m    data, unless an explicit score is passed in which case it is used instead.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    If `n_jobs` was set to a value higher than one, the data is copied for each\u001b[0m\n\u001b[0;34m    point in the grid (and not `n_jobs` times). This is done for efficiency\u001b[0m\n\u001b[0;34m    reasons if individual jobs take very little time, but may raise errors if\u001b[0m\n\u001b[0;34m    the dataset is large and not enough memory is available.  A workaround in\u001b[0m\n\u001b[0;34m    this case is to set `pre_dispatch`. Then, the memory is copied only\u001b[0m\n\u001b[0;34m    `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\u001b[0m\n\u001b[0;34m    n_jobs`.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    See Also\u001b[0m\n\u001b[0;34m    ---------\u001b[0m\n\u001b[0;34m    ParameterGrid : Generates all the combinations of a hyperparameter grid.\u001b[0m\n\u001b[0;34m    train_test_split : Utility function to split the data into a development\u001b[0m\n\u001b[0;34m        set usable for fitting a GridSearchCV instance and an evaluation set\u001b[0m\n\u001b[0;34m        for its final evaluation.\u001b[0m\n\u001b[0;34m    sklearn.metrics.make_scorer : Make a scorer from a performance metric or\u001b[0m\n\u001b[0;34m        loss function.\u001b[0m\n\u001b[0;34m\u001b[0m\n\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0m_required_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"estimator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"param_grid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2*n_jobs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m                 \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m            \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0m_check_param_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m        \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mFile:\u001b[0m           /srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/model_selection/_search.py\n\u001b[0;31mType:\u001b[0m           ABCMeta\n\u001b[0;31mSubclasses:\u001b[0m     \n"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\nmod.fit(X, y).predict(X).sum()","metadata":{"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"437"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer, precision_score, recall_score\n\ndef min_recall_precision(y_true, y_pred):\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\nmake_scorer(min_recall_precision, greater_is_better=False)\n# ?make_scorer","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"make_scorer(min_recall_precision, greater_is_better=False)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, make_scorer\n\ndef min_recall_precision(est, X, y_true, sample_weight=None):\n    y_pred = est.predict(X)\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\ngrid = GridSearchCV(\n    estimator=LogisticRegression(max_iter=1000),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n    scoring={'precision': make_scorer(precision_score), \n             'recall': make_scorer(recall_score),\n             'min_both': min_recall_precision},\n    refit='min_both',\n    return_train_score=True,\n    cv=10,\n    n_jobs=-1\n)\ngrid.fit(X, y);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" s = make_scorer(min_recall_precision)\n # ??s Ctrl+/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a summary for the test metrics.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall', 'mean_test_precision', 'mean_test_min_both']:\n    plt.plot([_[1] for _ in df_results['param_class_weight']], \n             df_results[score], \n             label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here's the train metrics.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_train_recall', 'mean_train_precision', 'mean_test_min_both']:\n    plt.scatter(x=[_[1] for _ in df_results['param_class_weight']], \n                y=df_results[score.replace('test', 'train')], \n                label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Outlier Detection Models","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.ensemble import IsolationForest\nmod = IsolationForest().fit(X)\nnp.where(mod.predict(X) == -1, 1, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now in a gridsearch.","metadata":{}},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == -1, 1, 0))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == -1, 1, 0))\n\ngrid = GridSearchCV(\n    estimator=IsolationForest(),\n    param_grid={'contamination': np.linspace(0.001, 0.02, 10)},\n    scoring={'precision': outlier_precision, \n             'recall': outlier_recall},\n    refit='precision',\n    cv=5,\n    n_jobs=-1\n)\ngrid.fit(X, y);\n\nplt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall', 'mean_test_precision']:\n    plt.plot(df_results['param_contamination'], \n             df_results[score], \n             label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def min_pre_rec(y, y_true):\n    return min(recall_score(y, y_true), precision_score(y, y_true))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == 1, 0, 1))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == 1, 0, 1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(\n    estimator=LogisticRegression(class_weight=10),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 40, t5)]},\n    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'min_pre_rec': make_scorer(min_pre_rec)},\n    refit='precision',\n    cv = 10,\n    n_jobs=-1\n)\ngrid.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_min_pre_rec']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = make_scorer(recall_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \n\nnp.eye(4)","metadata":{},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"array([[1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.]])"},"metadata":{}}]}]}