{"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# $ python -m pip install numpy\n# $ python -m pip install pandas\n# $ python -m pip install matplotlib\n# $ python -m pip install scikit-learn\n# $ python -m pip install keras\n# $ python -m pip install tensorflow","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pylab as plt\n\nbinder=0\nif bool(input(binder))== True:\n    df = pd.read_csv(\"creditcard.csv\")\nelse:\n    df  = pd.read_csv(\"C:/Users/Lenovo/OneDrive/Data Science project/Python.Data.Science/scikit-learn/scikit-metrics/creditcard.csv\")[:80_000]","metadata":{"scrolled":true,"tags":[],"trusted":true},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdin","text":"0 True\n"}]},{"cell_type":"code","source":"df.head(3)","metadata":{"scrolled":true,"tags":[],"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62    0.0  \n1  0.125895 -0.008983  0.014724    2.69    0.0  \n2 -0.139097 -0.055353 -0.059752  378.66    0.0  \n\n[3 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = df.drop(columns=['Time', 'Amount', 'Class']).values\ny = df['Class'].values\nf\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nmod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\nmod.fit(X, y).predict(X).sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def min_recall_precision(y_true, y_pred):\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\nmake_scorer(min_recall_precision, greater_is_better=False)\n# ?make_scorer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score, make_scorer\n\ndef min_recall_precision(est, X, y_true, sample_weight=None):\n    y_pred = est.predict(X)\n    recall = recall_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred)\n    return min(recall, precision)\n\ngrid = GridSearchCV(\n    estimator=LogisticRegression(max_iter=1000),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 20, 30)]},\n    scoring={'precision': make_scorer(precision_score), \n             'recall': make_scorer(recall_score),\n             'min_both': min_recall_precision},\n    refit='min_both',\n    return_train_score=True,\n    cv=10,\n    n_jobs=-1\n)\ngrid.fit(X, y);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# s = make_scorer(min_recall_precision)\n# ??s","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here's a summary for the test metrics.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall', 'mean_test_precision', 'mean_test_min_both']:\n    plt.plot([_[1] for _ in df_results['param_class_weight']], \n             df_results[score], \n             label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And here's the train metrics.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_train_recall', 'mean_train_precision', 'mean_test_min_both']:\n    plt.scatter(x=[_[1] for _ in df_results['param_class_weight']], \n                y=df_results[score.replace('test', 'train')], \n                label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using Outlier Detection Models","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.ensemble import IsolationForest\nmod = IsolationForest().fit(X)\nnp.where(mod.predict(X) == -1, 1, 0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now in a gridsearch.","metadata":{}},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == -1, 1, 0))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == -1, 1, 0))\n\ngrid = GridSearchCV(\n    estimator=IsolationForest(),\n    param_grid={'contamination': np.linspace(0.001, 0.02, 10)},\n    scoring={'precision': outlier_precision, \n             'recall': outlier_recall},\n    refit='precision',\n    cv=5,\n    n_jobs=-1\n)\ngrid.fit(X, y);\n\nplt.figure(figsize=(12, 4))\ndf_results = pd.DataFrame(grid.cv_results_)\nfor score in ['mean_test_recall', 'mean_test_precision']:\n    plt.plot(df_results['param_contamination'], \n             df_results[score], \n             label=score)\nplt.legend();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br><br><br><br><br><br><br><br><br><br><br><br>","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def min_pre_rec(y, y_true):\n    return min(recall_score(y, y_true), precision_score(y, y_true))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_precision(mod, X, y):\n    preds = mod.predict(X)\n    return precision_score(y, np.where(preds == 1, 0, 1))\n\ndef outlier_recall(mod, X, y):\n    preds = mod.predict(X)\n    return recall_score(y, np.where(preds == 1, 0, 1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(\n    estimator=LogisticRegression(class_weight=10),\n    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace(1, 40, t5)]},\n    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score), 'min_pre_rec': make_scorer(min_pre_rec)},\n    refit='precision',\n    cv = 10,\n    n_jobs=-1\n)\ngrid.fit(X, y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(grid.cv_results_)\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_recall'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_precision'])\nplt.plot([_[1] for _ in df['param_class_weight']], df['mean_test_min_pre_rec']);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = make_scorer(recall_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \n\nnp.eye(4)","metadata":{},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"array([[1., 0., 0., 0.],\n       [0., 1., 0., 0.],\n       [0., 0., 1., 0.],\n       [0., 0., 0., 1.]])"},"metadata":{}}]}]}